{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as sc\n",
    "import scipy.signal\n",
    "import scipy.io.wavfile\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.decomposition import PCA\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import *\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.optimizers import Adam\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "import skimage as ski\n",
    "import skimage.color\n",
    "import skimage.io\n",
    "import random\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "seed=42\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вкратце принцип такой:\n",
    "- в части train была предобработка аудио и обучение CNN и PCA\n",
    "- в начале этой части будет загрузка моделей и считывание мета файлов для работы с предобработанными аудио\n",
    "- далее из CNN берутся мета-фичи и спектр сжимается по PCA\n",
    "- эти два признака конкатенируются и подаются на полносвязную сеть\n",
    "- далее делается предсказание и сохранается результат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_meta = pd.read_csv('data/meta/meta.txt', header=None)\n",
    "df_meta.columns = ['filename', 'type', 'idk', 'duration', 'label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "door             3416\n",
       "tool             1659\n",
       "knocking_door    1656\n",
       "bags             1236\n",
       "keyboard         1225\n",
       "background       1126\n",
       "ring              713\n",
       "speech            276\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_num2str = pd.Series(df_meta.label.unique())\n",
    "class_str2num = pd.Series(range(0,len(class_num2str)))\n",
    "class_str2num.index = class_num2str.values\n",
    "\n",
    "df_meta.label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ---------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_proc_meta = pd.read_csv('proc_meta.csv')\n",
    "df_proc_meta['group'] = df_proc_meta.filename.apply(lambda x: str(x).split('.')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "door             882\n",
       "tool             471\n",
       "knocking_door    444\n",
       "keyboard         338\n",
       "bags             308\n",
       "background       302\n",
       "ring             188\n",
       "speech            67\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(seed)\n",
    "val_file = df_meta.loc[np.sort(np.random.choice(range(len(df_meta)), size=3000))]\n",
    "val_file.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 300, 257)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 150, 64)           82304     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 150, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 75, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 75, 64)            20544     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 75, 64)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 37, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 37, 128)           41088     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 37, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 18, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 18, 128)           49280     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 18, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 9, 128)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 9, 256)            98560     \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 9, 256)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 4, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 8200      \n",
      "=================================================================\n",
      "Total params: 1,349,576\n",
      "Trainable params: 1,349,576\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 48\n",
    "seed=42\n",
    "\n",
    "input_layer = Input(shape=(300,257))\n",
    "\n",
    "conv1 = Conv1D(64, 5, padding='same', strides=2, kernel_initializer=glorot_uniform(seed=seed))(input_layer)\n",
    "relu_1 = Activation('relu')(conv1)\n",
    "max_pool1 = MaxPooling1D(pool_size=2)(relu_1)\n",
    "\n",
    "conv2 = Conv1D(64, 5, padding='same', strides=1, kernel_initializer=glorot_uniform(seed=seed+1))(max_pool1)\n",
    "relu_2 = Activation('relu')(conv2)\n",
    "max_pool2 = MaxPooling1D(pool_size=2)(relu_2)\n",
    "\n",
    "conv3 = Conv1D(128, 5, padding='same', strides=1, kernel_initializer=glorot_uniform(seed=seed+2))(max_pool2)\n",
    "relu_3 = Activation('relu')(conv3)\n",
    "max_pool3 = MaxPooling1D(pool_size=2)(relu_3)\n",
    "\n",
    "conv4 = Conv1D(128, 3, padding='same', strides=1, kernel_initializer=glorot_uniform(seed=seed+3))(max_pool3)\n",
    "relu_4 = Activation('relu')(conv4)\n",
    "max_pool4 = MaxPooling1D(pool_size=2)(relu_4)\n",
    "\n",
    "conv5 = Conv1D(256, 3, padding='same', strides=1, kernel_initializer=glorot_uniform(seed=seed+4))(max_pool4)\n",
    "relu_5 = Activation('relu')(conv5)\n",
    "max_pool5 = MaxPooling1D(pool_size=2)(relu_5)\n",
    "\n",
    "flatten = Flatten()(max_pool5)\n",
    "\n",
    "dense_0 = Dense(1024, activation='sigmoid', kernel_initializer=glorot_uniform(seed=seed+5))(flatten)\n",
    "dense_out = Dense(8, activation='softmax', kernel_initializer=glorot_uniform(seed=seed+6))(dense_0)\n",
    "\n",
    "model = Model(inputs=[input_layer], outputs=[dense_out])\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights('2to5_1to2epochs.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### --- TEST ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_path='./data/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_labels = []\n",
    "test_files = []\n",
    "for file in os.listdir(test_path):\n",
    "    if file.find('unknown') == -1:\n",
    "        test_files.append(file)\n",
    "    if file.find('background') == 0:\n",
    "        test_labels.append(0)\n",
    "    if file.find('bags') == 0:\n",
    "        test_labels.append(1)\n",
    "    if file.find('door') == 0:\n",
    "        test_labels.append(2)\n",
    "    if file.find('keyboard') == 0:\n",
    "        test_labels.append(3)\n",
    "    if file.find('knocking_door') == 0:\n",
    "        test_labels.append(4)\n",
    "    if file.find('ring') == 0:\n",
    "        test_labels.append(5)\n",
    "    if file.find('speech') == 0:\n",
    "        test_labels.append(6)\n",
    "    if file.find('tool') == 0:\n",
    "        test_labels.append(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = dict()\n",
    "temp['filename'] = test_files[1:]\n",
    "temp['label'] = test_labels\n",
    "df_test_meta = pd.DataFrame.from_dict(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_proc_test_meta = pd.read_csv('proc_test_meta.csv')\n",
    "df_proc_test_meta['group'] = df_proc_test_meta.filename.apply(lambda x: str(x).split('.')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Widget Javascript not detected.  It may not be installed or enabled properly.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57995028ffd44c1282d58950522555a5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "path = './data/processed_test/'\n",
    "predictions = []\n",
    "files_queue = []\n",
    "p = np.zeros((1,300,257))\n",
    "for group in tqdm_notebook(df_proc_test_meta.group.unique()):\n",
    "    file_groups = df_proc_test_meta[df_proc_test_meta.group == group].filename\n",
    "    n = len(file_groups)\n",
    "    pred_file = np.zeros((n,8))\n",
    "    for i,file in enumerate(file_groups):\n",
    "        files_queue.append(file+'.png')\n",
    "        img = plt.imread(path+file+'.png')[:,:,0]\n",
    "        img = np.rot90(img)\n",
    "        p[0] = img\n",
    "        pred_file[i] = model.predict(p)\n",
    "    predictions.append(pred_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Widget Javascript not detected.  It may not be installed or enabled properly.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbe9d1d92dcb4b18894d154429386869"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Widget Javascript not detected.  It may not be installed or enabled properly.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3277fedbd9b4639b73430ff114cc8ba"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "features = np.zeros(shape=(len(df_meta), 8000))\n",
    "\n",
    "meaning = sc.io.wavfile.read(PATH+df_meta.filename[0]).\n",
    "\n",
    "PATH = 'data/audio/'\n",
    "labels = []\n",
    "files = []\n",
    "for i,file in enumerate(tqdm_notebook(df_meta.filename)):\n",
    "    sr,wave_data = sc.io.wavfile.read(PATH+file)\n",
    "    spectr = np.abs(np.fft.rfft(wave_data, n=sr))+10\n",
    "    spectr = spectr[1:]/np.max(spectr[1:])\n",
    "    labels.append(df_meta.iloc[i].label)\n",
    "    files.append(df_meta.iloc[i].filename)\n",
    "    if sr != 16000:\n",
    "        features[i] = spectr[:8000]\n",
    "    else:\n",
    "        features[i] = spectr\n",
    "    \n",
    "PATH = 'data/audio/'\n",
    "data_dict = dict()\n",
    "for i in tqdm_notebook(range(features.shape[1])):\n",
    "    data_dict[i] = features[:,i]\n",
    "    \n",
    "data_dict['label'] = labels\n",
    "data_dict['filename'] = files\n",
    "\n",
    "df_features = pd.DataFrame.from_dict(data_dict)\n",
    "df_features.label = df_features.label.map(class_str2num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('pca_params.pkl', 'rb') as handle:\n",
    "    pca = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_features_transf = pca.transform(df_features.drop(labels=['label', 'filename'], axis=1))\n",
    "train_features_transf = (train_features_transf - train_features_transf.min())/(train_features_transf - train_features_transf.min()).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "intermediate_layer_model = Model(inputs=model.layers[0].input,\n",
    "                                 outputs=model.layers[-2].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Widget Javascript not detected.  It may not be installed or enabled properly.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b788f0586ae1448cb107d3f69f1941a8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "path = './data/processed_audio/'\n",
    "train_meta_features = []\n",
    "files_queue = []\n",
    "p = np.zeros((1,300,257))\n",
    "for group in tqdm_notebook(df_proc_meta.group.unique()):\n",
    "    file_groups = df_proc_meta[df_proc_meta.group == group].filename\n",
    "    n = len(file_groups)\n",
    "    pred_file = np.zeros((n,1024))\n",
    "    for i,file in enumerate(file_groups):\n",
    "        files_queue.append(file+'.png')\n",
    "        img = plt.imread(path+file+'.png')[:,:,0]\n",
    "        img = np.rot90(img)\n",
    "        p[0] = img\n",
    "        pred_file[i] = intermediate_layer_model.predict(p)\n",
    "    train_meta_features.append(pred_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_mean_meta_features = np.zeros((len(train_meta_features), 1024))\n",
    "for i in range(len(train_meta_features)):\n",
    "    train_mean_meta_features[i] = train_meta_features[i].mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Widget Javascript not detected.  It may not be installed or enabled properly.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c89f5df222984af692108bd7d6120470"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "path = './data/processed_test/'\n",
    "test_meta_features = []\n",
    "files_queue = []\n",
    "p = np.zeros((1,300,257))\n",
    "for group in tqdm_notebook(df_proc_test_meta.group.unique()):\n",
    "    file_groups = df_proc_test_meta[df_proc_test_meta.group == group].filename\n",
    "    n = len(file_groups)\n",
    "    pred_file = np.zeros((n,1024))\n",
    "    for i,file in enumerate(file_groups):\n",
    "        files_queue.append(file+'.png')\n",
    "        img = plt.imread(path+file+'.png')[:,:,0]\n",
    "        img = np.rot90(img)\n",
    "        p[0] = img\n",
    "        pred_file[i] = intermediate_layer_model.predict(p)\n",
    "    test_meta_features.append(pred_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.hstack((train_features_transf, train_mean_meta_features))\n",
    "y = pd.get_dummies(df_features.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_X, test_X, train_Y, test_Y = train_test_split(X, y, test_size=0.2, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_mean_meta_features = np.zeros((len(test_meta_features), 1024))\n",
    "for i in range(len(test_meta_features)):\n",
    "    test_mean_meta_features[i] = test_meta_features[i].mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Widget Javascript not detected.  It may not be installed or enabled properly.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6780b6b1c4f4d4587421106d03d7728"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Widget Javascript not detected.  It may not be installed or enabled properly.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "427a82badd7a4351b6d31bc79726cabc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "features = np.zeros(shape=(len(df_test_meta), 8000))\n",
    "\n",
    "PATH = 'data/test/'\n",
    "labels = []\n",
    "files = []\n",
    "for i,file in enumerate(tqdm_notebook(df_test_meta.filename)):\n",
    "    sr,wave_data = sc.io.wavfile.read(PATH+file)\n",
    "    spectr = np.abs(np.fft.rfft(wave_data, n=sr))+10\n",
    "    spectr = spectr[1:]/np.max(spectr[1:])\n",
    "    labels.append(df_test_meta.iloc[i].label)\n",
    "    files.append(df_test_meta.iloc[i].filename)\n",
    "    if sr != 16000:\n",
    "        features[i] = spectr[:8000]\n",
    "    else:\n",
    "        features[i] = spectr\n",
    "    \n",
    "PATH = 'data/test/'\n",
    "data_dict = dict()\n",
    "for i in tqdm_notebook(range(features.shape[1])):\n",
    "    data_dict[i] = features[:,i]\n",
    "    \n",
    "data_dict['label'] = labels\n",
    "data_dict['filename'] = files\n",
    "\n",
    "df_test_features = pd.DataFrame.from_dict(data_dict)\n",
    "df_test_features.label = df_features.label.map(class_str2num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_features_transf = pca.transform(df_test_features.drop(labels=['label', 'filename'], axis=1))\n",
    "test_features_transf = (test_features_transf - test_features_transf.min())/(test_features_transf - test_features_transf.min()).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_TEST = np.hstack((test_features_transf, test_mean_meta_features))\n",
    "Y_TEST = pd.get_dummies(df_test_features.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# xgb_clf = xgb.XGBClassifier(max_depth=4, n_estimators=20, objective='multi:softmax', n_jobs=4, verbose=10, booster='gblinear')\n",
    "# train_X, test_X, train_Y, test_Y = train_test_split(X, df_features.label, test_size=0.2, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-mlogloss:0.369565\n",
      "[10]\tvalidation_0-mlogloss:0.023428\n",
      "[19]\tvalidation_0-mlogloss:0.021325\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gblinear', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=4, min_child_weight=1, missing=None, n_estimators=20,\n",
       "       n_jobs=4, nthread=None, objective='multi:softprob', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1, verbose=10)"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# xgb_clf.fit(train_X, train_Y.values, eval_set=[(test_X, test_Y)], eval_metric='mlogloss', verbose=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class_weight = {0:1, 1:1, 2:1, 3:1, 4:1, 5:1, 6:1, 7:2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9045 samples, validate on 2262 samples\n",
      "Epoch 1/10\n",
      " - 9s - loss: 0.9655 - categorical_accuracy: 0.8051 - val_loss: 0.2769 - val_categorical_accuracy: 0.9408\n",
      "Epoch 2/10\n",
      " - 4s - loss: 0.1781 - categorical_accuracy: 0.9776 - val_loss: 0.1118 - val_categorical_accuracy: 0.9766\n",
      "Epoch 3/10\n",
      " - 5s - loss: 0.0923 - categorical_accuracy: 0.9852 - val_loss: 0.0769 - val_categorical_accuracy: 0.9828\n",
      "Epoch 4/10\n",
      " - 5s - loss: 0.0661 - categorical_accuracy: 0.9883 - val_loss: 0.0591 - val_categorical_accuracy: 0.9850\n",
      "Epoch 5/10\n",
      " - 5s - loss: 0.0541 - categorical_accuracy: 0.9889 - val_loss: 0.0554 - val_categorical_accuracy: 0.9854\n",
      "Epoch 6/10\n",
      " - 4s - loss: 0.0460 - categorical_accuracy: 0.9904 - val_loss: 0.0432 - val_categorical_accuracy: 0.9907\n",
      "Epoch 7/10\n",
      " - 4s - loss: 0.0421 - categorical_accuracy: 0.9910 - val_loss: 0.0445 - val_categorical_accuracy: 0.9876\n",
      "Epoch 8/10\n",
      " - 4s - loss: 0.0377 - categorical_accuracy: 0.9909 - val_loss: 0.0411 - val_categorical_accuracy: 0.9881\n",
      "Epoch 9/10\n",
      " - 4s - loss: 0.0361 - categorical_accuracy: 0.9927 - val_loss: 0.0380 - val_categorical_accuracy: 0.9894\n",
      "Epoch 10/10\n",
      " - 4s - loss: 0.0334 - categorical_accuracy: 0.9925 - val_loss: 0.0341 - val_categorical_accuracy: 0.9903\n"
     ]
    }
   ],
   "source": [
    "perceptron = Sequential()\n",
    "perceptron.add(Dense(1024, input_dim=(2064), kernel_initializer=glorot_uniform(seed=seed+6)))\n",
    "perceptron.add(Activation('sigmoid'))\n",
    "perceptron.add(Dense(512, kernel_initializer=glorot_uniform(seed=seed+7)))\n",
    "perceptron.add(Activation('sigmoid'))\n",
    "perceptron.add(Dense(8, kernel_initializer=glorot_uniform(seed=seed+8)))\n",
    "perceptron.add(Activation('softmax'))\n",
    "perceptron.compile(loss='categorical_crossentropy',              \n",
    "              optimizer=Adam(lr=0.0001),              \n",
    "              metrics=['categorical_accuracy'])\n",
    "hist = perceptron.fit(train_X, train_Y, validation_data=(test_X, test_Y), shuffle=True, batch_size=48, \n",
    "                      epochs=10, verbose=2, class_weight=class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 5, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 5, 5, 0, 0, 0, 5, 5, 5, 6, 0, 0, 0, 6, 7, 0, 2, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 3, 1, 2, 1, 6, 6, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2,\n",
       "       2, 2, 2, 2, 2, 5, 5, 5, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 6, 2, 6,\n",
       "       2, 1, 2, 2, 2, 6, 6, 6, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 1, 3, 1, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 2, 4, 4, 4, 4, 4, 4,\n",
       "       6, 4, 4, 4, 4, 4, 4, 4, 4, 4, 0, 4, 6, 4, 4, 4, 6, 4, 4, 4, 4, 4,\n",
       "       4, 4, 5, 4, 4, 4, 4, 4, 4, 2, 4, 4, 4, 4, 4, 4, 4, 6, 6, 4, 4, 4,\n",
       "       4, 4, 4, 4, 5, 5, 5, 5, 6, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 5, 5,\n",
       "       5, 5, 0, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 3, 5,\n",
       "       5, 5, 5, 1, 5, 5, 5, 5, 5, 5, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "       6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "       4, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "       6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "       6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 4, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 4,\n",
       "       6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 2, 6, 6, 6, 6,\n",
       "       6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7,\n",
       "       6, 7, 7, 0, 7, 7, 7, 7, 7, 7, 7], dtype=int64)"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = perceptron.predict(X_TEST)\n",
    "pred.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.78947368, 0.91089109, 0.82608696, 0.94736842, 0.89285714,\n",
       "       0.89932886, 0.9209622 , 0.8       ])"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(df_test_meta.label.values, pred.argmax(axis=1), average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8733710440155085"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(df_test_meta.label.values, pred.argmax(axis=1), average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred_test = pd.DataFrame()\n",
    "df_pred_test['filename'] = df_test_meta.filename\n",
    "df_pred_test['confidence'] = pred.max(axis=1)\n",
    "df_pred_test['label'] = pred.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_path = 'data/test/'\n",
    "unknown_files = []\n",
    "for file in os.listdir(test_path):\n",
    "    if file.find('unknown') == 0:\n",
    "        unknown_files.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_unknown_meta = pd.DataFrame(unknown_files, columns=['filename'])\n",
    "df_unknown_meta['label'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd931619c3614d8a899293f6922fa806"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# UNCOMMENT THIS IF yYOU DONT DOWNLOAD proc_test_meta.csv\n",
    "\n",
    "# fn, lb, cnt = cropping_all(df_unknown_meta, read_path='data/test/', save_path='data/processed_unknown/')\n",
    "\n",
    "# tmp = dict()\n",
    "# tmp['filename'] = fn\n",
    "# tmp['label'] = lb\n",
    "\n",
    "# df_proc_unknown_meta = pd.DataFrame.from_dict(tmp)\n",
    "# df_proc_unknown_meta.to_csv('proc_unknown_meta.csv', encoding='UTF-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_proc_unknown_meta = pd.read_csv('proc_unknown_meta.csv')\n",
    "df_proc_unknown_meta['group'] = df_proc_unknown_meta.filename.apply(lambda x: str(x).split('.')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Widget Javascript not detected.  It may not be installed or enabled properly.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfab7f1f98d242e5b250b8ad7fc06939"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "path = './data/processed_unknown/'\n",
    "unknown_meta_features = []\n",
    "files_queue = []\n",
    "p = np.zeros((1,300,257))\n",
    "for group in tqdm_notebook(df_proc_unknown_meta.group.unique()):\n",
    "    file_groups = df_proc_unknown_meta[df_proc_unknown_meta.group == group].filename\n",
    "    n = len(file_groups)\n",
    "    pred_file = np.zeros((n,1024))\n",
    "    for i,file in enumerate(file_groups):\n",
    "        files_queue.append(file+'.png')\n",
    "        img = plt.imread(path+file+'.png')[:,:,0]\n",
    "        img = np.rot90(img)\n",
    "        p[0] = img\n",
    "        pred_file[i] = intermediate_layer_model.predict(p)\n",
    "    unknown_meta_features.append(pred_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unknown_mean_meta_features = np.zeros((len(unknown_meta_features), 1024))\n",
    "for i in range(len(unknown_meta_features)):\n",
    "    unknown_mean_meta_features[i] = unknown_meta_features[i].mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Widget Javascript not detected.  It may not be installed or enabled properly.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbb4c2163a9f4073a96d4ca59ef88269"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Widget Javascript not detected.  It may not be installed or enabled properly.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a179a322bfbd4661bf071290cb957108"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "features = np.zeros(shape=(len(df_unknown_meta), 8000))\n",
    "\n",
    "PATH = 'data/test/'\n",
    "labels = []\n",
    "files = []\n",
    "for i,file in enumerate(tqdm_notebook(df_unknown_meta.filename)):\n",
    "    sr,wave_data = sc.io.wavfile.read(PATH+file)\n",
    "    spectr = np.abs(np.fft.rfft(wave_data, n=sr))+10\n",
    "    spectr = spectr[1:]/np.max(spectr[1:])\n",
    "    labels.append(df_unknown_meta.iloc[i].label)\n",
    "    files.append(df_unknown_meta.iloc[i].filename)\n",
    "    if sr != 16000:\n",
    "        features[i] = spectr[:8000]\n",
    "    else:\n",
    "        features[i] = spectr\n",
    "    \n",
    "PATH = 'data/test/'\n",
    "data_dict = dict()\n",
    "for i in tqdm_notebook(range(features.shape[1])):\n",
    "    data_dict[i] = features[:,i]\n",
    "    \n",
    "data_dict['label'] = labels\n",
    "data_dict['filename'] = files\n",
    "\n",
    "df_unknown_features = pd.DataFrame.from_dict(data_dict)\n",
    "df_unknown_features.label = df_unknown_features.label.map(class_str2num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unknown_features_transf = pca.transform(df_unknown_features.drop(labels=['filename', 'label'], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unknown_features_transf = (unknown_features_transf - unknown_features_transf.min())/(unknown_features_transf - unknown_features_transf.min()).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_unknown = np.hstack((unknown_features_transf, unknown_mean_meta_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = perceptron.predict(X_unknown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "background       0\n",
       "bags             1\n",
       "door             2\n",
       "keyboard         3\n",
       "knocking_door    4\n",
       "ring             5\n",
       "speech           6\n",
       "tool             7\n",
       "dtype: int32"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_str2num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred_unknown = pd.DataFrame()\n",
    "df_pred_unknown['filename'] = df_unknown_meta.filename\n",
    "df_pred_unknown['confidence'] = pred.max(axis=1)\n",
    "df_pred_unknown['label'] = pred.argmax(axis=1)\n",
    "df_pred_unknown.label = df_pred_unknown.label.map(class_num2str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pred = pd.concat((df_pred_test, df_pred_unknown))\n",
    "df_pred.to_csv('result.txt', sep='\\t', encoding='UTF-8', index=False, header=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
